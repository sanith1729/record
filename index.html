<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Screen + Mic Recorder</title>
</head>
<body>
  <h2>Record Screen with Microphone</h2>
  <video id="preview" autoplay muted style="width: 100%;"></video>
  <br />
  <button id="start">Start Recording</button>
  <button id="stop" disabled>Stop Recording</button>
  <a id="download" style="display: none;">Download</a>

  <script>
    const startBtn = document.getElementById("start");
    const stopBtn = document.getElementById("stop");
    const downloadLink = document.getElementById("download");
    const preview = document.getElementById("preview");

    let mediaRecorder;
    let recordedChunks = [];

    startBtn.onclick = async () => {
      try {
        // Request screen stream (with audio) and microphone stream
        const screenStream = await navigator.mediaDevices.getDisplayMedia({
          video: true,
          audio: true
        });

        const micStream = await navigator.mediaDevices.getUserMedia({
          audio: true
        });

        // Debug: log available audio tracks
        console.log("Screen audio tracks:", screenStream.getAudioTracks());
        console.log("Mic audio tracks:", micStream.getAudioTracks());

        const audioContext = new AudioContext();
        if (audioContext.state === 'suspended') {
          await audioContext.resume();
        }
        const destination = audioContext.createMediaStreamDestination();

        // Connect system audio if available
        if (screenStream.getAudioTracks().length > 0) {
          const systemSource = audioContext.createMediaStreamSource(screenStream);
          systemSource.connect(destination);
        } else {
          console.warn("No system audio track available from screen share.");
        }

        // Connect microphone audio if available
        if (micStream.getAudioTracks().length > 0) {
          const micSource = audioContext.createMediaStreamSource(micStream);
          micSource.connect(destination);
        } else {
          console.warn("No microphone audio track available.");
        }

        // Combine video from screen and mixed audio from the AudioContext
        const combinedStream = new MediaStream([
          ...screenStream.getVideoTracks(),
          ...destination.stream.getAudioTracks()
        ]);

        preview.srcObject = combinedStream;

        // Set up recording of the combined stream
        mediaRecorder = new MediaRecorder(combinedStream);
        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) recordedChunks.push(e.data);
        };

        mediaRecorder.onstop = () => {
          const blob = new Blob(recordedChunks, { type: "video/webm" });
          const url = URL.createObjectURL(blob);
          downloadLink.href = url;
          downloadLink.download = "recording.webm";
          downloadLink.style.display = "inline";
          recordedChunks = [];
        };

        mediaRecorder.start();
        startBtn.disabled = true;
        stopBtn.disabled = false;
      } catch (e) {
        console.error("Error accessing media devices:", e);
      }
    };

    stopBtn.onclick = () => {
      mediaRecorder.stop();
      startBtn.disabled = false;
      stopBtn.disabled = true;
    };
  </script>
</body>
</html>
v
